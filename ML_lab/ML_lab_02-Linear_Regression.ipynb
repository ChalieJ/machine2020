{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "### 학생의 공부시간과 획득 점수를 예측해본다\n",
    "\n",
    "x = 공부시간\n",
    "y = 0 ~ 100점 사이 \n",
    "\n",
    "regression\n",
    "\n",
    "|x(hours)| y(score)|\n",
    "|--------|---------|\n",
    "|10|90|\n",
    "|9|80|\n",
    "|3|50|\n",
    "|2|30|\n",
    "\n",
    "위의 데이터를 가지고, 모델을 만들고 학습을 하고, \\\n",
    "새로운데이터(7시간 공부한 학생)의 스코어(점수)를 예측한다.\n",
    "\n",
    "|x|y|\n",
    "|-|-|\n",
    "|1|1|\n",
    "|2|2|\n",
    "|3|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATaElEQVR4nO3df6zddZ3n8edrylVuxNhZuQnltoo7mhoVtXKXwSXZEHQDOgQaZDI1GRWjaeIOUbMTJmI2mCGbZRwSnRmZDKkDGXAcxSBpKgtpMAxxnI0Mt7RQsXa3O3FCCxuuYEHilaH1vX/cw3g5nPvpvbf3e88pfT6SE74/PuecV7/w5dXv93zP96SqkCRpIb8x7ACSpNFmUUiSmiwKSVKTRSFJarIoJElNFoUkqanzokiyJsnuJHcNWPfqJLcnOZDkgSRndZ1HkrQ0q3FE8Rlg3wLrPgH8rKreDHwZ+OIq5JEkLUGnRZFkPfA7wF8vMOQy4Nbe9B3A+5Kky0ySpKU5pePX/zPgj4DXLrB+EngMoKqOJHkGeD3w0/mDkmwFtgK85jWvOeetb31rZ4El6ZVo165dP62qieU8t7OiSHIJ8GRV7UpywULDBix72T1FqmobsA1gamqqpqenVyynJJ0MkvzLcp/b5amn84FLk/wE+CZwYZK/7RtzENgAkOQU4HXA0x1mkiQtUWdFUVXXVNX6qjoL2ALcV1W/3zdsB/Cx3vQVvTHepVCSRkjXn1G8TJLrgOmq2gHcDHwtyQHmjiS2rHYeSVLbqhRFVd0P3N+bvnbe8l8Cv7saGSRJy+M3syVJTRaFJKnJopAkNVkUkqQmi0KS1GRRSJKaLApJUpNFIUlqsigkSU0WhSSpyaKQJDVZFJKkJotCktRkUUiSmiwKSVKTRSFJarIoJElNFoUkqamzokhyapJ/SvJwkkeT/PGAMVcmmUmyp/f4ZFd5JEnL0+VvZj8PXFhVzyUZA76f5J6q+kHfuNur6qoOc0iSjkNnRVFVBTzXmx3rPaqr95MkdaPTzyiSrEmyB3gSuLeqHhgw7ENJHklyR5INXeaRJC1dp0VRVUer6t3AeuDcJO/oG/Id4KyqeifwXeDWQa+TZGuS6STTMzMzXUaWJPVZlauequowcD9wcd/yp6rq+d7sV4FzFnj+tqqaqqqpiYmJTrNKkl6qy6ueJpKs7U2PA+8Hftw3Zt282UuBfV3lkSQtT5dXPa0Dbk2yhrlC+lZV3ZXkOmC6qnYAn05yKXAEeBq4ssM8kqRlyNzFSSeOqampmp6eHnYMSTqhJNlVVVPLea7fzJYkNVkUkqQmi0KS1GRRSJKaLApJUpNFIUlqsigkSU0WhSSpyaKQJDVZFJKkJotCktRkUUiSmiwKSVKTRSFJarIoJElNFoUkqcmikCQ1WRSSpCaLQpLUdEpXL5zkVOB7wKt773NHVX2hb8yrgduAc4CngN+rqp90lUnS6Nu++xA37NzP44dnOXPtOFdftJHNmyaHHeuk1uURxfPAhVX1LuDdwMVJzusb8wngZ1X1ZuDLwBc7zCNpxG3ffYhr7tzLocOzFHDo8CzX3LmX7bsPDTvaSa2zoqg5z/Vmx3qP6ht2GXBrb/oO4H1J0lUmSaPthp37mX3h6EuWzb5wlBt27h9SIkHHn1EkWZNkD/AkcG9VPdA3ZBJ4DKCqjgDPAK8f8Dpbk0wnmZ6ZmekysqQhevzw7JKWa3V0WhRVdbSq3g2sB85N8o6+IYOOHvqPOqiqbVU1VVVTExMTXUSVNALOXDu+pOVaHaty1VNVHQbuBy7uW3UQ2ACQ5BTgdcDTq5FJ0ui5+qKNjI+tecmy8bE1XH3RxiElEnRYFEkmkqztTY8D7wd+3DdsB/Cx3vQVwH1V9bIjCkknh82bJrn+8rOZXDtOgMm141x/+dle9TRknV0eC6wDbk2yhrlC+lZV3ZXkOmC6qnYANwNfS3KAuSOJLR3mkXQC2Lxp0mIYMZ0VRVU9AmwasPzaedO/BH63qwySpOPnN7MlSU0WhSSpyaKQJDVZFJKkJotCktRkUUiSmiwKSVKTRSFJarIoJElNFoUkqcmikCQ1WRSSpCaLQpLUZFFIkposCklSk0UhSWqyKCRJTRaFJKmps6JIsiHJ3yfZl+TRJJ8ZMOaCJM8k2dN7XDvotSRJw9PZb2YDR4A/rKqHkrwW2JXk3qr6Ud+4f6iqSzrMIUk6Dp0dUVTVE1X1UG/658A+YLKr95MkdWNVPqNIchawCXhgwOr3Jnk4yT1J3r7A87cmmU4yPTMz02FSSVK/zosiyWnAt4HPVtWzfasfAt5YVe8CvgJsH/QaVbWtqqaqampiYqLbwJKkl+i0KJKMMVcSX6+qO/vXV9WzVfVcb/puYCzJ6V1mkiQtTZdXPQW4GdhXVV9aYMwZvXEkObeX56muMkmSlq7Lq57OBz4C7E2yp7fs88AbAKrqJuAK4FNJjgCzwJaqqg4zSZKWqLOiqKrvAznGmBuBG7vKIEk6fn4zW5LUZFFIkposCklSk0UhSWqyKCRJTRaFJKnJopAkNVkUkqQmi0KS1GRRSJKaLApJUpNFIUlqsigkSU0WhSSpyaKQJDVZFJKkJotCktRkUUiSmjr7KdQkG4DbgDOAXwHbqurP+8YE+HPgg8AvgCur6qGuMkld2b77EDfs3M/jh2c5c+04V1+0kc2bJocdS1oRnRUFcAT4w6p6KMlrgV1J7q2qH80b8wHgLb3HbwN/1fundMLYvvsQ19y5l9kXjgJw6PAs19y5F8Cy0CvCMU89JbkqyW8u9YWr6okXjw6q6ufAPqB/r7kMuK3m/ABYm2TdUt9LGqYbdu7/t5J40ewLR7lh5/4hJZJW1mI+ozgDeDDJt5Jc3DtdtCRJzgI2AQ/0rZoEHps3f5CXlwlJtiaZTjI9MzOz1LeXOvX44dklLZdONMcsiqr6b8ydGroZuBL4P0n+R5LfWswbJDkN+Dbw2ap6tn/1oLcckGFbVU1V1dTExMRi3lZaNWeuHV/SculEs6irnqqqgP/XexwBfhO4I8mftp6XZIy5kvh6Vd05YMhBYMO8+fXA44vJJI2Kqy/ayPjYmpcsGx9bw9UXbRxSImllLeYzik8n2QX8KfCPwNlV9SngHOBDjeeFuaOQfVX1pQWG7QA+mjnnAc9U1RNL/UNIw7R50yTXX342k2vHCTC5dpzrLz/bD7L1irGYq55OBy6vqn+Zv7CqfpXkksbzzgc+AuxNsqe37PPAG3rPvwm4m7lLYw8wd3nsx5cWXxoNmzdNWgx6xTpmUVTVtY11+xrrvs/gzyDmjyngD46VQZI0PH4zW5LUZFFIkposCklSk0UhSWqyKCRJTRaFJKnJopAkNVkUkqQmi0KS1GRRSJKaLApJUpNFIUlqsigkSU0WhSSpyaKQJDVZFJKkJotCktRkUUiSmjoriiS3JHkyyQ8XWH9BkmeS7Ok9FvzJVUnS8BzzN7OPw98ANwK3Ncb8Q1Vd0mEGSdJx6uyIoqq+Bzzd1etLklbHsD+jeG+Sh5Pck+TtCw1KsjXJdJLpmZmZ1cwnSSe9YRbFQ8Abq+pdwFeA7QsNrKptVTVVVVMTExOrFlCSNMSiqKpnq+q53vTdwFiS04eVR5I02NCKIskZSdKbPreX5alh5ZEkDdbZVU9JvgFcAJye5CDwBWAMoKpuAq4APpXkCDALbKmq6iqPJGl5OiuKqvrwMdbfyNzls5KkETbsq54kSSPOopAkNVkUkqQmi0KS1GRRSJKaLApJUpNFIUlqsigkSU0WhSSpyaKQJDVZFJKkJotCktRkUUiSmiwKSVKTRSFJarIoJElNFoUkqcmikCQ1dVYUSW5J8mSSHy6wPkn+IsmBJI8keU9XWfRy23cf4vw/uY83fe5/cv6f3Mf23YeGHUnSiOryiOJvgIsb6z8AvKX32Ar8VYdZNM/23Ye45s69HDo8SwGHDs9yzZ17LQtJA3VWFFX1PeDpxpDLgNtqzg+AtUnWdZVHv3bDzv3MvnD0JctmXzjKDTv3DymRpFE2zM8oJoHH5s0f7C17mSRbk0wnmZ6ZmVmVcK9kjx+eXdJySSe3YRZFBiyrQQOraltVTVXV1MTERMexXvnOXDu+pOWSTm7DLIqDwIZ58+uBx4eU5aRy9UUbGR9b85Jl42NruPqijUNKJGmUDbModgAf7V39dB7wTFU9McQ8J43Nmya5/vKzmVw7ToDJteNcf/nZbN408MyfpJPcKV29cJJvABcApyc5CHwBGAOoqpuAu4EPAgeAXwAf7yqLXm7zpkmLQdKidFYUVfXhY6wv4A+6en9J0srwm9mSpCaLQpLUZFFIkposCklSk0UhSWqyKCRJTRaFJKnJopAkNVkUkqQmi0KS1GRRSJKaLApJUpNFIUlqsigkSU0WhSSpyaKQJDVZFJKkJotCktTUaVEkuTjJ/iQHknxuwPork8wk2dN7fLLLPJKkpevsN7OTrAH+EvjPwEHgwSQ7qupHfUNvr6qrusohSTo+XR5RnAscqKp/rqp/Bb4JXNbh+0mSOtBlUUwCj82bP9hb1u9DSR5JckeSDR3mkSQtQ5dFkQHLqm/+O8BZVfVO4LvArQNfKNmaZDrJ9MzMzArHlCS1dFkUB4H5RwjrgcfnD6iqp6rq+d7sV4FzBr1QVW2rqqmqmpqYmOgkrCRpsC6L4kHgLUnelORVwBZgx/wBSdbNm70U2NdhHknSMnR21VNVHUlyFbATWAPcUlWPJrkOmK6qHcCnk1wKHAGeBq7sKo8kaXlS1f+xwWibmpqq6enpYceQpBNKkl1VNbWc5/rNbElSk0UhSWqyKCRJTRaFJKnJopAkNVkUkqQmi0KS1GRRSJKaLApJUpNFIUlqsigkSU0WhSSpyaKQJDVZFJKkJotCktRkUUiSmiwKSVKTRSFJarIoJElNnRZFkouT7E9yIMnnBqx/dZLbe+sfSHJWl3kkSUvXWVEkWQP8JfAB4G3Ah5O8rW/YJ4CfVdWbgS8DX+wqjyRpebo8ojgXOFBV/1xV/wp8E7isb8xlwK296TuA9yVJh5kkSUt0SoevPQk8Nm/+IPDbC42pqiNJngFeD/x0/qAkW4Gtvdnnk/ywk8Qr63T6/hwjypwr60TIeSJkBHOutI3LfWKXRTHoyKCWMYaq2gZsA0gyXVVTxx+vW+ZcWeZcOSdCRjDnSksyvdzndnnq6SCwYd78euDxhcYkOQV4HfB0h5kkSUvUZVE8CLwlyZuSvArYAuzoG7MD+Fhv+grgvqp62RGFJGl4Ojv11PvM4SpgJ7AGuKWqHk1yHTBdVTuAm4GvJTnA3JHElkW89LauMq8wc64sc66cEyEjmHOlLTtn/Au8JKnFb2ZLkposCklS08gWxYly+49F5LwyyUySPb3HJ4eQ8ZYkTy70/ZPM+Yven+GRJO9Z7Yy9HMfKeUGSZ+Zty2uHkHFDkr9Psi/Jo0k+M2DM0LfnInOOwvY8Nck/JXm4l/OPB4wZ+r6+yJxD39fnZVmTZHeSuwasW/r2rKqRezD34ff/Bf498CrgYeBtfWP+C3BTb3oLcPuI5rwSuHHI2/M/Ae8BfrjA+g8C9zD3vZbzgAdGNOcFwF1D3pbrgPf0pl8L/O8B/86Hvj0XmXMUtmeA03rTY8ADwHl9Y0ZhX19MzqHv6/Oy/Ffg7wb9+13O9hzVI4oT5fYfi8k5dFX1PdrfT7kMuK3m/ABYm2Td6qT7tUXkHLqqeqKqHupN/xzYx9wdBuYb+vZcZM6h622j53qzY71H/xU2Q9/XF5lzJCRZD/wO8NcLDFny9hzVohh0+4/+/8hfcvsP4MXbf6ymxeQE+FDvFMQdSTYMWD9si/1zjIL39g7/70ny9mEG6R2yb2Lub5fzjdT2bOSEEdievdMke4AngXurasHtOcR9fTE5YTT29T8D/gj41QLrl7w9R7UoVuz2Hx1bTIbvAGdV1TuB7/LrJh8lo7AtF+Mh4I1V9S7gK8D2YQVJchrwbeCzVfVs/+oBTxnK9jxGzpHYnlV1tKrezdzdG85N8o6+ISOxPReRc+j7epJLgCeraldr2IBlze05qkVxotz+45g5q+qpqnq+N/tV4JxVyrYUi9neQ1dVz754+F9VdwNjSU5f7RxJxpj7n+/Xq+rOAUNGYnseK+eobM95eQ4D9wMX960ahX393yyUc0T29fOBS5P8hLlT4Rcm+du+MUvenqNaFCfK7T+OmbPv3PSlzJ0rHjU7gI/2rtY5D3imqp4Ydqh+Sc548VxqknOZ++/3qVXOEObuKLCvqr60wLChb8/F5ByR7TmRZG1vehx4P/DjvmFD39cXk3MU9vWquqaq1lfVWcz9/+i+qvr9vmFL3p5d3j122aq7238MI+enk1wKHOnlvHK1cyb5BnNXuJye5CDwBeY+jKOqbgLuZu5KnQPAL4CPr3bGRea8AvhUkiPALLBlCH85OB/4CLC3d74a4PPAG+blHIXtuZico7A91wG3Zu6Hzn4D+FZV3TVq+/oicw59X1/I8W5Pb+EhSWoa1VNPkqQRYVFIkposCklSk0UhSWqyKCRJTRaFJKnJopAkNVkU0nFK8h96N4I7Nclrer9X0H8fIOmE5RfupBWQ5L8DpwLjwMGqun7IkaQVY1FIK6B3r68HgV8C/7Gqjg45krRiPPUkrYx/B5zG3K/JnTrkLNKK8ohCWgFJdjB3W+c3Aeuq6qohR5JWzEjePVY6kST5KHCkqv6ud3fR/5Xkwqq6b9jZpJXgEYUkqcnPKCRJTRaFJKnJopAkNVkUkqQmi0KS1GRRSJKaLApJUtP/B6IDKc05kjJVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = [1, 2, 3]\n",
    "y = [1, 2, 3]\n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "plt.xlim(0, 4)\n",
    "plt.ylim(0, 4)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Hypothesis\n",
    "\n",
    "H(x) = Wx + b\n",
    "일차방정식으로 가설을 세운다.\n",
    "\n",
    "위의 경우 H(x) = 1 * 1 + 0 으로 나옴\n",
    "\n",
    "일차방정식과 실제데이터간의 거리가 가까울수록 W와 B값이 좋은 값이다.\n",
    "우리가 세운 가설과 실제데이터가 얼마나 다른지 확인 - cost function 혹은 loss function\n",
    "\n",
    "제곱을 많이 해준다. 차이를 모두 양수로 변환할 수 있어 장점\n",
    "\n",
    "코스트 펑션 : 각 좌표의 값을 코스트 펑션에 넣어 각 좌표의 갯수로 나누어 평균을 내준다.\n",
    "\n",
    "\n",
    "W와 b를 최소화하는! minimized cost\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "주어진 x의 값을 어떻게 예측할 것인가? => Hypothesis \\\n",
    "weight과 곱한값에 bios를 합한값이다.\n",
    "\n",
    "## Cost function\n",
    "\n",
    "Hypothesis로 예측한 값이 실제의 값과 얼마나 차이가 있는가? \\\n",
    "W와 b값을 달리하여 cost값을 가장 작게 만드는것 => 학습한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.2495892 [0.11271621] [0.46127373]\n",
      "20 0.08606521 [0.64627457] [0.6559654]\n",
      "40 0.06042178 [0.7097329] [0.64574]\n",
      "60 0.054715153 [0.7278339] [0.61735433]\n",
      "80 0.049691718 [0.7410493] [0.58852774]\n",
      "100 0.04513082 [0.7532596] [0.56088686]\n",
      "120 0.040988494 [0.76485926] [0.5345289]\n",
      "140 0.037226427 [0.7759104] [0.50940824]\n",
      "160 0.033809636 [0.7864418] [0.48546797]\n",
      "180 0.030706456 [0.79647833] [0.4626527]\n",
      "200 0.02788809 [0.80604297] [0.44090974]\n",
      "220 0.02532841 [0.8151583] [0.42018864]\n",
      "240 0.023003662 [0.8238452] [0.40044132]\n",
      "260 0.020892313 [0.8321238] [0.3816221]\n",
      "280 0.018974738 [0.8400134] [0.36368725]\n",
      "300 0.017233165 [0.8475322] [0.3465953]\n",
      "320 0.01565143 [0.8546975] [0.33030662]\n",
      "340 0.0142148705 [0.8615262] [0.31478345]\n",
      "360 0.012910171 [0.868034] [0.29998985]\n",
      "380 0.011725233 [0.87423587] [0.28589144]\n",
      "400 0.010649044 [0.8801463] [0.2724556]\n",
      "420 0.009671628 [0.88577896] [0.25965118]\n",
      "440 0.008783936 [0.89114696] [0.2474485]\n",
      "460 0.007977711 [0.89626265] [0.23581934]\n",
      "480 0.0072454778 [0.90113795] [0.2247367]\n",
      "500 0.006580466 [0.9057841] [0.21417493]\n",
      "520 0.0059764865 [0.91021186] [0.2041095]\n",
      "540 0.005427941 [0.9144316] [0.1945171]\n",
      "560 0.0049297414 [0.9184531] [0.1853755]\n",
      "580 0.00447727 [0.9222855] [0.17666349]\n",
      "600 0.004066329 [0.9259377] [0.16836096]\n",
      "620 0.0036931082 [0.9294183] [0.16044863]\n",
      "640 0.0033541338 [0.93273544] [0.15290815]\n",
      "660 0.003046275 [0.93589664] [0.14572203]\n",
      "680 0.0027666797 [0.93890935] [0.13887365]\n",
      "700 0.0025127437 [0.9417803] [0.13234708]\n",
      "720 0.0022821196 [0.94451636] [0.12612726]\n",
      "740 0.0020726596 [0.9471239] [0.12019978]\n",
      "760 0.0018824198 [0.94960886] [0.11455086]\n",
      "780 0.0017096432 [0.9519771] [0.1091674]\n",
      "800 0.0015527286 [0.954234] [0.10403691]\n",
      "820 0.0014102068 [0.9563848] [0.09914756]\n",
      "840 0.0012807766 [0.9584346] [0.09448802]\n",
      "860 0.0011632205 [0.960388] [0.09004743]\n",
      "880 0.0010564592 [0.96224964] [0.08581552]\n",
      "900 0.0009594891 [0.96402377] [0.08178248]\n",
      "920 0.0008714241 [0.96571445] [0.077939]\n",
      "940 0.0007914384 [0.96732575] [0.07427616]\n",
      "960 0.0007188003 [0.96886134] [0.07078548]\n",
      "980 0.0006528225 [0.9703248] [0.06745879]\n",
      "1000 0.0005929067 [0.97171944] [0.06428844]\n",
      "1020 0.0005384833 [0.9730485] [0.06126713]\n",
      "1040 0.0004890636 [0.9743151] [0.05838779]\n",
      "1060 0.00044417256 [0.9755222] [0.05564378]\n",
      "1080 0.00040340595 [0.97667253] [0.05302875]\n",
      "1100 0.0003663793 [0.97776884] [0.05053661]\n",
      "1120 0.0003327534 [0.97881365] [0.04816161]\n",
      "1140 0.00030221313 [0.9798091] [0.04589828]\n",
      "1160 0.00027447392 [0.9807582] [0.04374124]\n",
      "1180 0.0002492813 [0.98166245] [0.04168556]\n",
      "1200 0.00022640095 [0.9825242] [0.0397265]\n",
      "1220 0.00020562306 [0.9833455] [0.03785951]\n",
      "1240 0.00018674844 [0.98412824] [0.03608026]\n",
      "1260 0.0001696089 [0.9848741] [0.03438464]\n",
      "1280 0.00015404013 [0.98558503] [0.03276868]\n",
      "1300 0.00013990248 [0.98626244] [0.03122865]\n",
      "1320 0.00012706146 [0.9869081] [0.02976104]\n",
      "1340 0.00011539888 [0.9875233] [0.02836239]\n",
      "1360 0.00010480756 [0.9881097] [0.02702947]\n",
      "1380 9.518867e-05 [0.98866844] [0.02575921]\n",
      "1400 8.645214e-05 [0.98920107] [0.02454863]\n",
      "1420 7.851756e-05 [0.98970836] [0.02339498]\n",
      "1440 7.1311406e-05 [0.9901921] [0.02229561]\n",
      "1460 6.476425e-05 [0.99065316] [0.02124774]\n",
      "1480 5.8821835e-05 [0.9910924] [0.02024915]\n",
      "1500 5.3421303e-05 [0.991511] [0.0192975]\n",
      "1520 4.8518286e-05 [0.99191] [0.01839059]\n",
      "1540 4.4064785e-05 [0.99229014] [0.01752628]\n",
      "1560 4.002047e-05 [0.9926525] [0.01670261]\n",
      "1580 3.6347974e-05 [0.9929978] [0.01591765]\n",
      "1600 3.3011507e-05 [0.99332684] [0.01516958]\n",
      "1620 2.9980854e-05 [0.99364054] [0.01445665]\n",
      "1640 2.7229771e-05 [0.9939394] [0.01377723]\n",
      "1660 2.4730025e-05 [0.9942242] [0.01312975]\n",
      "1680 2.2460574e-05 [0.99449563] [0.01251272]\n",
      "1700 2.0399368e-05 [0.9947543] [0.0119247]\n",
      "1720 1.85269e-05 [0.9950009] [0.01136425]\n",
      "1740 1.6826047e-05 [0.99523586] [0.01083012]\n",
      "1760 1.5281586e-05 [0.99545974] [0.01032112]\n",
      "1780 1.3879292e-05 [0.9956731] [0.00983605]\n",
      "1800 1.2605301e-05 [0.9958765] [0.00937378]\n",
      "1820 1.1448164e-05 [0.99607027] [0.00893324]\n",
      "1840 1.0397539e-05 [0.9962549] [0.00851342]\n",
      "1860 9.442911e-06 [0.99643093] [0.00811331]\n",
      "1880 8.576562e-06 [0.99659866] [0.007732]\n",
      "1900 7.788856e-06 [0.9967586] [0.00736861]\n",
      "1920 7.0741776e-06 [0.9969109] [0.00702229]\n",
      "1940 6.424862e-06 [0.99705607] [0.00669225]\n",
      "1960 5.8349433e-06 [0.9971944] [0.00637774]\n",
      "1980 5.299748e-06 [0.9973262] [0.00607804]\n",
      "2000 4.81306e-06 [0.9974519] [0.00579241]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 데이터 셋팅\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "# Variable - tensorflow가 사용하는 변수\n",
    "w = tf.Variable(tf.random_normal([1]), name='weight')    # [1] : shape 1\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# hypothesis 셋팅\n",
    "hypothesis = x_train * w + b\n",
    "\n",
    "# cost/loss function 셋팅\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))    # reduce_mean : 평균\n",
    "\n",
    "# cost를 minimize 하는 방법\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)    # 무엇을 minimize 할것인가?\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(w), sess.run(b))\n",
    "        \n",
    "# 회차가 거듭될 수록 cost는 낮아짐, weight 은 1에 가까워짐, bias는 0에 가까워짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10.712462 [0.28962117] [0.11614249]\n",
      "20 0.085159585 [1.1850946] [0.41572163]\n",
      "40 0.07418133 [1.176807] [0.46159765]\n",
      "60 0.06478308 [1.1652452] [0.503412]\n",
      "80 0.056575637 [1.1544232] [0.5424829]\n",
      "100 0.049407892 [1.1443099] [0.5789953]\n",
      "120 0.043148287 [1.1348588] [0.6131163]\n",
      "140 0.03768169 [1.1260269] [0.64500284]\n",
      "160 0.032907687 [1.1177733] [0.67480093]\n",
      "180 0.028738534 [1.1100602] [0.70264757]\n",
      "200 0.025097603 [1.1028522] [0.7286705]\n",
      "220 0.02191792 [1.0961164] [0.7529891]\n",
      "240 0.019141082 [1.0898217] [0.7757152]\n",
      "260 0.016716016 [1.0839392] [0.7969529]\n",
      "280 0.014598246 [1.078442] [0.81679964]\n",
      "300 0.012748731 [1.0733048] [0.83534676]\n",
      "320 0.011133572 [1.068504] [0.85267895]\n",
      "340 0.009723041 [1.0640175] [0.8688763]\n",
      "360 0.008491198 [1.0598251] [0.8840127]\n",
      "380 0.0074154497 [1.055907] [0.8981579]\n",
      "400 0.006475956 [1.0522456] [0.9113766]\n",
      "420 0.005655496 [1.048824] [0.9237297]\n",
      "440 0.004938989 [1.0456265] [0.93527377]\n",
      "460 0.004313253 [1.0426384] [0.94606185]\n",
      "480 0.003766813 [1.039846] [0.9561432]\n",
      "500 0.0032895696 [1.0372365] [0.9655644]\n",
      "520 0.0028728093 [1.0347978] [0.9743689]\n",
      "540 0.002508853 [1.0325189] [0.98259646]\n",
      "560 0.0021909876 [1.0303891] [0.99028546]\n",
      "580 0.0019134113 [1.0283989] [0.9974708]\n",
      "600 0.0016709927 [1.0265391] [1.0041856]\n",
      "620 0.0014592835 [1.0248009] [1.0104605]\n",
      "640 0.0012744077 [1.0231767] [1.0163245]\n",
      "660 0.0011129545 [1.0216589] [1.0218043]\n",
      "680 0.00097195164 [1.0202404] [1.0269254]\n",
      "700 0.0008488052 [1.0189148] [1.0317115]\n",
      "720 0.0007412729 [1.0176761] [1.0361837]\n",
      "740 0.0006473524 [1.0165184] [1.0403633]\n",
      "760 0.000565332 [1.0154365] [1.0442691]\n",
      "780 0.0004937049 [1.0144255] [1.0479189]\n",
      "800 0.00043116516 [1.0134809] [1.0513296]\n",
      "820 0.0003765418 [1.012598] [1.0545169]\n",
      "840 0.00032883618 [1.0117731] [1.0574957]\n",
      "860 0.00028717596 [1.0110022] [1.060279]\n",
      "880 0.00025079708 [1.0102816] [1.0628803]\n",
      "900 0.00021901811 [1.0096081] [1.0653116]\n",
      "920 0.00019126922 [1.0089788] [1.0675833]\n",
      "940 0.00016703605 [1.0083908] [1.0697064]\n",
      "960 0.00014587196 [1.0078412] [1.0716903]\n",
      "980 0.00012739314 [1.0073277] [1.0735444]\n",
      "1000 0.00011125436 [1.0068479] [1.075277]\n",
      "1020 9.715878e-05 [1.0063994] [1.0768961]\n",
      "1040 8.485014e-05 [1.0059803] [1.0784092]\n",
      "1060 7.410068e-05 [1.0055887] [1.079823]\n",
      "1080 6.471298e-05 [1.0052227] [1.0811443]\n",
      "1100 5.6515804e-05 [1.0048807] [1.0823792]\n",
      "1120 4.935389e-05 [1.004561] [1.0835333]\n",
      "1140 4.310193e-05 [1.0042623] [1.0846115]\n",
      "1160 3.7641912e-05 [1.0039833] [1.0856192]\n",
      "1180 3.28735e-05 [1.0037224] [1.086561]\n",
      "1200 2.8707782e-05 [1.0034786] [1.0874411]\n",
      "1220 2.50731e-05 [1.0032508] [1.0882634]\n",
      "1240 2.1895135e-05 [1.0030379] [1.089032]\n",
      "1260 1.9119503e-05 [1.0028389] [1.0897509]\n",
      "1280 1.6696606e-05 [1.0026529] [1.0904223]\n",
      "1300 1.4580821e-05 [1.0024791] [1.0910496]\n",
      "1320 1.2733915e-05 [1.0023168] [1.0916357]\n",
      "1340 1.1120688e-05 [1.002165] [1.0921834]\n",
      "1360 9.712225e-06 [1.0020233] [1.0926952]\n",
      "1380 8.481247e-06 [1.0018908] [1.0931736]\n",
      "1400 7.4070203e-06 [1.0017669] [1.0936208]\n",
      "1420 6.468301e-06 [1.0016512] [1.0940386]\n",
      "1440 5.6488752e-06 [1.001543] [1.0944291]\n",
      "1460 4.9328164e-06 [1.0014421] [1.0947939]\n",
      "1480 4.3083164e-06 [1.0013475] [1.0951349]\n",
      "1500 3.7623297e-06 [1.0012593] [1.0954535]\n",
      "1520 3.2855685e-06 [1.0011768] [1.0957512]\n",
      "1540 2.8698616e-06 [1.0010998] [1.0960292]\n",
      "1560 2.506394e-06 [1.0010278] [1.0962892]\n",
      "1580 2.1886044e-06 [1.0009606] [1.0965321]\n",
      "1600 1.9114443e-06 [1.0008976] [1.0967591]\n",
      "1620 1.6698608e-06 [1.000839] [1.0969713]\n",
      "1640 1.457802e-06 [1.000784] [1.0971696]\n",
      "1660 1.2732826e-06 [1.0007327] [1.0973549]\n",
      "1680 1.1121663e-06 [1.0006846] [1.097528]\n",
      "1700 9.712394e-07 [1.0006399] [1.0976899]\n",
      "1720 8.482958e-07 [1.0005981] [1.0978411]\n",
      "1740 7.408728e-07 [1.0005589] [1.0979825]\n",
      "1760 6.470982e-07 [1.0005224] [1.0981145]\n",
      "1780 5.65262e-07 [1.0004882] [1.0982378]\n",
      "1800 4.936598e-07 [1.0004562] [1.098353]\n",
      "1820 4.3098612e-07 [1.0004264] [1.0984609]\n",
      "1840 3.767293e-07 [1.0003985] [1.0985615]\n",
      "1860 3.2901954e-07 [1.0003723] [1.0986556]\n",
      "1880 2.8736054e-07 [1.0003481] [1.0987436]\n",
      "1900 2.50935e-07 [1.0003253] [1.0988257]\n",
      "1920 2.1915093e-07 [1.0003039] [1.0989025]\n",
      "1940 1.9149434e-07 [1.0002842] [1.0989742]\n",
      "1960 1.673032e-07 [1.0002655] [1.0990413]\n",
      "1980 1.4608591e-07 [1.0002483] [1.099104]\n",
      "2000 1.2761699e-07 [1.0002319] [1.0991626]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Variable - tensorflow가 사용하는 변수\n",
    "w = tf.Variable(tf.random_normal([1]), name='weight')    # [1] : shape 1\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "# 데이터 셋팅\n",
    "x = tf.placeholder(tf.float32, shape=[None])\n",
    "y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# hypothesis 셋팅\n",
    "hypothesis = x * w + b\n",
    "\n",
    "# cost/loss function 셋팅\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))    # reduce_mean : 평균\n",
    "\n",
    "# cost를 minimize 하는 방법\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)    # 무엇을 minimize 할것인가?\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, w_val, b_val, _ = sess.run([cost, w, b, train],\n",
    "                                        feed_dict={x: [1, 2, 3, 4, 5],\n",
    "                                                   y: [2.1, 3.1, 4.1, 5.1 ,6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, w_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1003213]\n",
      "[3.5997434]\n",
      "[2.599512  4.5999746]\n"
     ]
    }
   ],
   "source": [
    "# 트레이닝 결과 확인\n",
    "print(sess.run(hypothesis, feed_dict={x: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={x: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={x: [1.5, 3.5]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
